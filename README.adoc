= streams-perf

A bare bones example of how to setup streams (Kafka) v1.2 on openshift using an external TLS client which uses client side TLS for authorization.
Note these instructions use the following configuration:

* Red Hat internal https://docs.google.com/document/d/1HOahEzLRdKiKC-TSfBaTGtoi1jiJetkh8CDF_pSeCaw/edit[env]
* project/namespace: kafka
* kafka cluster name: my-cluster
* topics: my-topic (20 partitions / 3 replicas)

Prereqs:

* JDK 1.8
* OpenSSL
* Kafka

NOTE: In order to install the cluster operator a user with cluster administrator

== Install cluster operator

After logging into openshift via the cli create a new project
----
oc new-project kafka
----

Create the cluster operator in the kafka project/namespace
----
oc apply -f install/cluster-operator -n kafka
oc apply -f examples/templates/cluster-operator -n kafka
----

== Install and configure kafka cluster

Create the kafka cluster in the name space
----
oc apply -f examples/kafka/kafka-persistent.yaml
----

Create a topic (make sure the 3 zookeeper and 3 kafka pods are started)
----
oc apply -f examples/topic/kafka-topic.yaml
----

Create TLS based users
----
oc apply -f examples/user/kafka-user.yaml
----

== Install and configure perf clients
=== Use the client directory for  all perf client activity
----
cd client
----
=== Install openshift secrets into key and trust store
----
rm *.crt *.key *.jks *.pkcs12
oc extract secret/my-cluster-cluster-ca-cert --keys ca.crt
keytool -keystore client-truststore.jks -alias CARoot -import -file ca.crt
oc extract secret/my-user --confirm
openssl pkcs12 -inkey user.key -in user.crt -CAfile ca.key -export -name client -out client.pkcs12
keytool -importkeystore -srckeystore client.pkcs12 -srcstoretype pkcs12 -destkeystore client-keystore.jks -deststoretype pkcs12
----
=== Modify Configuration
Modify the `consumer.properties` and `producer.properties` to meet your environment configuration

=== Execute the producer performance test

Note: You must have kafka installed locally and its `bin` directory is included in the `PATH` environment variable

----
kafka-producer-perf-test.sh --producer.config producer.properties --throughput 15000000 --num-records 15000 --record-size 5000 --topic my-topic
kafka-consumer-perf-test.sh --consumer.config consumer.properties --topic my-topic --group my-group --messages 15 --timeout 9999999999 --threads 20 --broker-list=https://my-cluster-kafka-0-kafka.apps.cluster-tracs-ebca.tracs-ebca.open.redhat.com:443,https://my-cluster-kafka-1-kafka.apps.cluster-tracs-ebca.tracs-ebca.open.redhat.com:443,https://my-cluster-kafka-2-kafka.apps.cluster-tracs-ebca.tracs-ebca.open.redhat.com:443

----


== Delete cluster
The kafka cluster can be deleted with
----
oc delete kafka my-cluster
----