= streams-perf

A bare bones example of how to setup streams (Kafka) v1.2 on openshift using an external TLS client which uses client side TLS for authorization.
Note these instructions use the following configuration:

* Red Hat internal https://docs.google.com/document/d/1HOahEzLRdKiKC-TSfBaTGtoi1jiJetkh8CDF_pSeCaw/edit[env]
* project/namespace: kafka
* kafka cluster name: my-cluster
* topics: my-topic (20 partitions / 3 replicas)

Prereqs:

* JDK 1.8
* OpenSSL

NOTE: In order to install the cluster operator a user with cluster administrator

== Install cluster operator

After logging into openshift via the cli create a new project
----
oc new-project kafka
----

Create the cluster operator in the kafka project/namespace
----
oc apply -f install/cluster-operator -n kafka
oc apply -f examples/templates/cluster-operator -n kafka
----

== Install and configure kafka cluster

Create the kafka cluster in the name space
----
oc apply -f examples/kafka/kafka-persistent.yaml
----

Create a topic (make sure the 3 zookeeper and 3 kafka pods are started)
----
oc apply -f examples/topic/kafka-topic.yaml
----

Create TLS based users
----
oc apply -f examples/user/kafka-user.yaml
----

== Install and configure perf clients
=== Use the client directory for  all perf client activity
----
cd client/bin
----
=== Install openshift secrets into key and trust store
----
rm  -f *.crt *.key *.jks *.pkcs12
oc extract secret/my-cluster-cluster-ca-cert --keys ca.crt
keytool -keystore client-truststore.jks -alias CARoot -import -file ca.crt
oc extract secret/my-user --confirm
openssl pkcs12 -inkey user.key -in user.crt -export -name client -out client.pkcs12
keytool -importkeystore -srckeystore client.pkcs12 -srcstoretype pkcs12 -destkeystore client-keystore.jks -deststoretype pkcs12
----
=== Modify Configuration
Modify the `consumer.properties` and `producer.properties` to meet your environment configuration

=== Execute the producer performance test

Note: You must have kafka installed locally and its `bin` directory is included in the `PATH` environment variable

----
./kafka-producer-perf-test.sh --producer.config producer.properties --throughput 15000 --num-records 150000 --record-size 5000 --topic my-topic
./kafka-consumer-perf-test.sh --consumer.config consumer.properties --topic my-topic --group my-group --messages 150000 --timeout 9999999999 --threads 20 --broker-list=https://my-cluster-kafka-0-kafka.apps.cluster-e6db.sandbox239.opentlc.com:443,https://my-cluster-kafka-1-kafka.apps.cluster-e6db.sandbox239.opentlc.com:443,https://my-cluster-kafka-2-kafka.apps.cluster-e6db.sandbox239.opentlc.com:443

----

== Delete topics and clusters
Delete topic, user and cluster with sample below
----
oc delete kafkauser my-user
oc delete kafkatopic my-topic
oc delete kafka my-cluster
----